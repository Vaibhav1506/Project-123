# -*- coding: utf-8 -*-
"""Project 123.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13g-AEe8ckyDInEMyJlt-etUsZrFGTeYP
"""

import cv2
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.datasets import fetch_openml
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

X , y = fetch_openml("mnist_784", version = 1, return_X_y = True)

print(pd.Series(y).value_counts())

classes = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']

nclass = len(classes) 

samples_per_class = 5
figure = plt.figure(figsize = (len_class * 2, (1 + samples_per_class * 2)))

idx_cls = 0
for cls in classes:
  idxs = np.flatnonzero(y == cls)
  idxs = np.random.choice(idxs, samples_per_class, replace = False)
  i = 0
  for idx in idxs:
    plt_idx = i * nclasses + idx_cls + 1
    p = plt.subplot(samples_per_class, nclasses, plt_idx);
    p = sns.heatmap(np.reshape(X[idx], (22,30)), cmap = plt.cm.gray, xticklabels = False, yticklabels = False, cbar = False);
    p = plt.axis('off');
    i += 1
  idx_cls += 1

print(len(X))

print(len(X.loc[0]))

print(X.loc[0])
print(y.loc[0])

X_train, X_test, Y_train, Y_test = train_test_split(X, y, random_state = 9, train_size = 7500, test_size = 2500)

X_train_scaled = X_train / 255.0
X_test_scaled = X_test / 255.0 

clf = LogisticRegression(solver = "saga",  multi_class = "multinomial").fit(X_train_scaled, Y_train)

Y_prediction = clf.predict(X_test_scaled)

accuracy = accuracy_score(Y_test, Y_prediction)

print("The accuracy of the data set is:", accuracy*100 , "%")